#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# For the people of Smubworld!
import urllib2
import os
import time
from optparse import OptionParser
import sys
import sqlite3
import hashlib
import gzip
import socket
__program__ = 'blockfinder'
__url__ = 'https://github.com/ioerror/blockfinder/'
__author__ = 'Jacob Appelbaum <jacob@appelbaum.net>, David <db@d1b.org>'
__copyright__ = 'Copyright (c) 2010'
__license__ = 'See LICENSE for licensing information'
__version__ = '3.1415'

try:
    import GeoIP
except ImportError:
     GeoIP = None

try:
    from future import antigravity
except ImportError:
    antigravity = None

try:
    import IPy
except ImportError:
    IPy = None
try:
    import ipaddr as Ipaddr
except ImportError:
    Ipaddr = None

def ip_address_to_dec(ip_addr):
    octets = ip_addr.split('.')
    return long(''.join(["%02X" % long(octet) for octet in octets]), 16)

def return_first_ip_and_number_in_inetnum(line):
    start_ip = line.split("-")[0].strip()
    end_ip = line.split("-")[1].strip()
    num_ips = 1 + (ip_address_to_dec(end_ip) - ip_address_to_dec(start_ip) )
    return start_ip, num_ips

def ipv4_address_valid(ip_addr):
    ipv4arr = ip_addr.split('.')
    if len(ipv4arr) == 4:
        for items in ipv4arr:
            if int(items) > 255:
                return False
        return True
    else:
        return False

def calculate_ipv4_subnet(host_count):
    if host_count <= 1:
        return 32
    return 34 - len(bin(host_count - 1))


class BlockFinderError(Exception):
    pass

class DatabaseCache:
    def __init__(self, cache_dir, verbose=False):
        self.cache_dir = cache_dir
        self.verbose = verbose
        self.cursor = None
        self.conn = None

    def connect_to_database(self):
        if not os.path.exists(self.cache_dir):
            if self.verbose:
                print "Initializing the cache directory..."
            os.mkdir(self.cache_dir)
        self.conn = sqlite3.connect(self.cache_dir + "sqlitedb")
        self.cursor = self.conn.cursor()

    def commit_and_close_database(self):
        self.conn.commit()
        self.cursor.close()

    def create_sql_database(self):
        """ Creates a new sqlite database.
            Existing delegation entries are dropped prior to inserting
            'newer' delegations.
        """
        sql_script_comp = []
        sql_script_comp.append("""drop table if exists delegations""" )
        sql_script_comp.append("""create table delegations(registry text, cc text, start text, value INTEGER, date text, status text, type text)""")
        sql_script_comp.append("""create table if not exists lir_record(cc text, start text, value INTEGER, type INTEGER)""")
        self.cursor.executescript(";\n".join(sql_script_comp) + ";" )
        self.conn.commit()

    def insert_into_sql_database(self, rows):
        """ inserts delegation information into the sqlite database"""
        text = """INSERT INTO delegations (registry, cc, start, value, date, status, type) VALUES (?,?,?,?,?,?,?)"""
        self.cursor.executemany(text, rows)
        self.conn.commit()

    def _get_total_delegations_from_db(self):
        """ Returns the total count of the number of entries in the ipv4, ipv6 and asn table """
        self.cursor.execute("""select count (*) from delegations""")
        return int (self.cursor.fetchone()[0] )

    def _get_possible_match_entries(self, cc):
        """ Get the count of 'possible' matching delegation entries"""
        self.cursor.execute("""select count (*)  from delegations where cc=?""", cc)
        return int (self.cursor.fetchone()[0] )

    def use_sql_database(self, request, cc):
        """ Use the sqlite database that is created after fetching delegations
            to output information for a given request """
        if self.verbose:
            print "We have %d entries in our delegation cache." % self._get_total_delegations_from_db()
        text = "select start, value from delegations where type=? and cc=?"
        cc = (cc,)
        self.cursor.execute(text, (request, cc[0]) )
        result = []
        for row in self.cursor:
            if request == "ipv4":
                if Ipaddr:
                    first = Ipaddr.IPv4Address(str(row[0]))
                    last = Ipaddr.IPv4Address(int(first) + int(row[1]) - 1)
                    result += [str(x) for x in Ipaddr.summarize_address_range(first, last)]
                else:
                    result.append(str(row[0]) + "/" + str(calculate_ipv4_subnet(int(row[1]))))
            elif request == "ipv6":
                result.append(str(row[0]) + "/" + str(int(row[1])))
            else:
                result.append(str(int(row[0])))
        result.sort()
        if self.verbose:
            result.append("We found %d possible entries in our delegation cache." % self._get_possible_match_entries(cc) )
            self.cursor.execute("""select count(*) from delegations where cc=? and type=?""", (cc[0], request) )
            result.append("We found %d matching entries in our delegation cache." % int (self.cursor.fetchone()[0] ) )
        return result

    def _rir_or_lir_lookup_ipv4(self, ip_addr, lookup_type):
        ipv4arr = ip_addr.split('.')
        if lookup_type == 'rir':
            self.cursor.execute('select cc, start, value from delegations WHERE type="ipv4" and start LIKE ?', ( ipv4arr[0] + "." + ipv4arr[1] + ".%",))
        else:
            self.cursor.execute('select * from lir_record WHERE start LIKE ? and type=4', (ipv4arr[0] + "." + ipv4arr[1] + ".%",))
        row = self.cursor.fetchone()

        if row is None:
            if lookup_type == "rir":
                self.cursor.execute('select cc, start, value from delegations WHERE type="ipv4" and start LIKE ? ', (ipv4arr[0] + ".%",))
            else:
                self.cursor.execute('select * from lir_record WHERE start LIKE ? and type=4', (ipv4arr[0] + ".%",))
            row = self.cursor.fetchone()

        while(row is not None):
            if (ip_address_to_dec(row[1]) <= ip_address_to_dec(ip_addr) < (ip_address_to_dec(row[1]) + row[2])):
                return row[0]
            row = self.cursor.fetchone()

    def rir_lookup(self, ip_addr):
        return self._rir_or_lir_lookup_ipv4(ip_addr, "rir")

    def lir_lookup(self, ip_addr):
        return self._rir_or_lir_lookup_ipv4(ip_addr, "lir")

    def asn_lookup(self, asn):
        self.cursor.execute('select cc from delegations WHERE type="asn" and start LIKE ?', (asn,))
        row = self.cursor.fetchone()
        if row:
            return row[0]

    def rir_or_lir_lookup_ipv6(self, ip_addr, ip_query, type_q):
        if type_q == "RIR":
            self.cursor.execute("select cc, start, value from delegations where type='ipv6'and start like ?", (ip_query,) )
        else:
            self.cursor.execute("select cc, start, value from lir_record where type=6 and start like ?", (ip_query,) )
        for row in self.cursor:
            try:
                if IPy and ip_addr in IPy.IP(row[1] + "/" + str(row[2])):
                    return row[0]
            except ValueError, e:
                if self.verbose:
                    print e
                pass

    def create_or_replace_lir_table_in_db(self):
        self.cursor.execute("""drop table if exists lir_record """)
        self.cursor.execute("""create table if not exists lir_record(cc text, start text, value INTEGER, type INTEGER)""")
        self.conn.commit()

    def insert_lir_delegation(self, data):
        insert_text = """insert into lir_record (cc, start, value, type) VALUES (?,?,?,?)"""
        self.cursor.execute(insert_text, data)
        self.conn.commit()

class DownloaderParser:
    def __init__(self, cache_dir, database_cache, user_agent, verbose=False):
        self.cache_dir = cache_dir
        self.database_cache = database_cache
        self.user_agent = user_agent
        self.verbose = verbose

    def update_progress_bar(self, percent_done, caption=""):
        """Write a progress bar to the console"""
        rows, columns = map(int, os.popen('stty size', 'r').read().split())
        width = columns - 4 - len(caption)
        sys.stdout.write("[%s>%s] %s\x1b[G" % (
                                        "=" * int(percent_done*width),
                                        "." * (width - int(percent_done * width)),
                                        caption) )
        sys.stdout.flush()

    # XXX TODO:allow the use of a proxy
    # Set up a proper Request object, set the user agent and if desired, a proxy
    def fetch(self, url):
        """ Fetch (with progress meter) and return the contents of a url. """
        req = urllib2.Request(url)
        req.add_header('User-Agent', self.user_agent)
        #req.set_proxy(host, type)
        fetcher = urllib2.urlopen(req)
        length_header = fetcher.headers.get("Content-Length")
        if length_header == None:
            """ The server did not provide a Content-Length header. """
            length_header = -1
        length = int(length_header)
        print "Fetching ", str (round(float(length/1024),2)) , " kilobytes"
        ret = ""
        t_start = time.time()
        while True:
            t_delta = time.time() - t_start
            if t_delta == 0:
                t_delta = 1
            if length_header != -1:
                self.update_progress_bar( float(len(ret)) / length,
                    "%.2f K/s" % (len(ret) / 1024 / t_delta) )
            tmp = fetcher.read(1024)
            if len(tmp) == 0:
                if len(ret) != length and length_header != -1:
                    raise Exception("Expected %s bytes, only received %s" % (
                                    len(ret), length ))
                print ""
                return ret
            ret += tmp

    def write_to_a_text_file(self, file_loc, data):
        f = open(file_loc, 'w')
        f.write(data)
        f.close()

    def extract_data_from_gzip_file(self, gzip_file_loc, extract_file_loc):
        gzip_file = gzip.open(gzip_file_loc, 'rb')
        gunzipped_file = open(extract_file_loc, 'w')
        while True:
            gunzipped_data = gzip_file.read(1024)
            if gunzipped_data == "":
                break
            gunzipped_file.writelines(gunzipped_data)
        gzip_file.close()
        gunzipped_file.close()

    def read_data_from_binary_file(self, fname):
        f = open(fname, 'rb')
        data = f.read()
        f.close()
        return data

    def create_blockfinder_cache_dir(self):
        if not os.path.exists(self.cache_dir):
            if self.verbose:
                print "Initializing the cache directory..."
            os.mkdir(self.cache_dir)

    def cache_delegation(self, delegation_url):
        """ Attempt to cache the contents of a delegation url in our cache dir. """
        delegation = ""
        print "Fetching " + delegation_url
        delegation = self.fetch(delegation_url)
        tmp = delegation_url.split('/')
        delegation_file = str(self.cache_dir) + str(tmp[-1])
        try:
            self.write_to_a_text_file(delegation_file, delegation)
            return True
        except Exception, e:
            print repr(e)
            return False

    def cache_is_dated(self, cached_files):
        """ Returns True if the mtime of any files in cache dir is > 24hrs."""
        try:
            os.stat(self.cache_dir)
        except OSError, e:
            print "\nDid you initialize the cache directory?\n"
            raise e
        for file in cached_files:
            fstat = os.stat(self.cache_dir + file)
            if (time.time() - fstat.st_mtime) > 86400:
                return True
        return False


    def get_md5_from_delegation_md5_file(self, delegation_file):
        """ Returns the md5sum from the delegation md5 file
            if it doesn't exist it returns an empty string"""
        checksum = ""
        try:
            f = open(self.cache_dir + delegation_file + ".md5", "r")
            checksum = f.read()
            f.close()
            if "=" in checksum:
                pos = checksum.find("=") +2
                checksum = str (checksum[pos:-1])
        except Exception, e:
            print repr(e)
        return checksum

    def verify_delegation_file(self, delegation_file):
        """ compares the delegation file md5sum to that of the provided md5sum
           returns True if they match otherwise returns False """
        checksum = ""
        checksum_of_file = ""
        try:
            data = self.read_data_from_binary_file(self.cache_dir + delegation_file)
            checksum_of_file = str (hashlib.md5(data).hexdigest() )
        except Exception, e:
            print repr(e)
        checksum = self.get_md5_from_delegation_md5_file(delegation_file)
        if checksum != checksum_of_file:
            return False
        if checksum == checksum_of_file and checksum != "":
            return True
        return False

    def verify_cache(self, delegation_files):
        """ if in verbose mode prints the result of checking the checksum of the
            delegation files """
        for file in delegation_files:
            if self.verbose:
                print "verifying " + file
            if self.verify_delegation_file(file):
                if self.verbose:
                    print "the md5 checksum of " + file + " *matches* the provided checksum"
            else:
                if self.verbose:
                    print "the md5 checksum of " + file + " does *not* match the provided checksum"

    def update_delegation_cache(self, delegation_urls):
        """ Fetch multiple delegation urls and cache the contents. """
        print "Updating delegation cache..."

        for url in delegation_urls.split():
            self.cache_delegation(url + ".md5")
            if self.verify_delegation_file(url.rpartition('/')[-1]):
                pass
            else:
                self.cache_delegation(url)

    def update_lir_delegation_cache(self, delegation_urls):
        """ Fetch multiple LIR delegation urls and cache the contents. """
        print "Updating LIR delegation cache..."
        for url in delegation_urls.split():
            self.cache_delegation(url)
        self.unpack_a_delegation_cache(delegation_urls, "LIR")

    def unpack_a_delegation_cache(self, delegation_urls, del_type=""):
        """ Unpack the fetched LIR delegation files into the blockfinder cache. """
        # This probably should unlink the gzip'ed file if we care about space...
        for url in delegation_urls.split():
            gzip_filename = url.rpartition('/')[-1]
            gunziped_filename = gzip_filename.rpartition('.')[0]
            if self.verbose:
                print "Unpacking " + del_type + "file " + gzip_filename + " into our cache as " + gunziped_filename
            self.extract_data_from_gzip_file(self.cache_dir + gzip_filename, self.cache_dir + gunziped_filename)

    def update_geoip_cache(self, geoip_urls):
        """ Fetch country level resolution GeoIP files from a given url and cache
        the contents. Unpack it if it's compressed. """
        print "Updating GeoIP cache..."
        for url in geoip_urls.split():
            self.cache_delegation(url)
        self.unpack_a_delegation_cache(geoip_urls, "GeoIP")

    def load_delegation(self, delegation_file):
        """ Load, parse and store the delegation file contents as a list. """
        keys = "registry cc type start value date status"
        try:
            f = open(delegation_file, "r")
            delegations = [ dict((k,v) for k,v in zip(keys.split(), line.strip().split("|")))
                            for line in f.readlines() if not line.startswith("#")]
            f.close()
            return delegations
        except OSError, e:
            print repr(e)

    def load_all_delegations(self, delegation_urls):
        """ Load all delegations into memory. """
        delegations = []
        for url in delegation_urls.split():
            filename = url.rpartition('/')[-1]
            if self.verbose:
                print "Attempting to load delegation file into memory: " + filename
            delegations.append(self.load_delegation(self.cache_dir + filename))
        return delegations

    def download_country_code_file(self):
        """ Download and save the latest opencountrycode TXT(';' - separated) file """
        url = "http://www.iso.org/iso/list-en1-semic-3.txt"
        text_content = urllib2.urlopen(url).read()
        self.write_to_a_text_file(self.cache_dir + "countrycodes.txt", text_content)

    def extract_info_from_lir_file_and_insert_into_sqlite(self, filename):
        block = []
        country = ""
        entry = False
        version = ""
        for line in open(self.cache_dir + filename, "r"):
            line = line.replace("\n", "")
            if line == "":
                entry = False
                country, block, version = "", [], ""
            elif not entry and "inetnum:" in line:
                try:
                    line = line.replace("inetnum:", "").strip()
                    start_ip, num_ips = return_first_ip_and_number_in_inetnum(line)
                    block = [start_ip, num_ips]
                    entry = True
                    version = "4"
                except Exception, e:
                    if self.verbose:
                        print repr(e), line
            elif not entry and "inet6num:" in line:
                try:
                    block = line.replace("inet6num:", "").strip().split("/")
                    entry = True
                    version = "6"
                except Exception, e:
                    if self.verbose:
                        print repr(e), line
            elif entry and "country:" in line:
                country = line.replace("country:", "").strip()
                data = (country, block[0], block[1], version )
                self.database_cache.insert_lir_delegation(data)

    def create_db_and_insert_delegation_into_db(self, delegation_urls):
        self.database_cache.create_sql_database()
        delegations = self.load_all_delegations(delegation_urls)
        rows = []
        for delegation in delegations:
            for entry in delegation:
                registry = str(entry['registry'])
                if not registry.isdigit() and str (entry['cc']) !="*":
                    temp_row = [entry['registry'], entry['cc'], entry['start'], \
                        entry['value'], entry['date'], entry['status'], entry['type']]
                    rows.append(temp_row)
        self.database_cache.insert_into_sql_database(rows)

class Lookup:
    def __init__(self, cache_dir, database_cache, verbose=False):
        self.cache_dir = cache_dir
        self.database_cache = database_cache
        self.verbose = verbose

    def build_country_code_dictionary(self):
        """ Return a dictionary mapping country name to the country code"""
        map_co = {}
        txt_file = str(self.cache_dir) + "countrycodes.txt"
        for line in open(txt_file, 'r'):
            line = line.replace("\n", "").replace("\r", "")
            if line.startswith("This list states the country"):
                continue
            if line == "" or ";" not in line:
                continue
            name, code = line.split(";")
            """ capitalize the individual parts of the country name """
            name = ' '.join([part.capitalize() for part in name.split(" ")])
            map_co[name] = code
        return map_co

    def get_name_from_country_code(self, cc_code):
        map_co = self.build_country_code_dictionary()
        country_name = [(key, value) for (key, value) in map_co.items() if value == cc_code]
        if len(country_name) > 0:
            return country_name[0][0]

    def get_country_code_from_name(self, country_name):
        """ Return the country code for a given country name. """
        map_co = self.build_country_code_dictionary()
        cc_code = [map_co[key] for key in map_co.keys() if key.upper().startswith(country_name.upper())]
        if len(cc_code) > 0:
            return cc_code[0]

    def geoip_lookup(self, ip_addr):
        # This would work with the CVS version of the GeoIP code
        # However, MaxMind hasn't done a release in a long time.
        # http://geoip.cvs.sourceforge.net/viewvc/geoip/python/test_v6.py?revision=1.1&view=markup
        #        gi = GeoIP.open(self.cache_dir + "GeoIPv6.dat",GeoIP.GEOIP_STANDARD)
        #        cc = gi.country_code_by_addr_v6(ip_addr)
        #        cc_name = gi.country_name_by_addr_v6(ip_addr)
        gi = GeoIP.open(self.cache_dir + "GeoIP.dat",GeoIP.GEOIP_STANDARD)
        cc = gi.country_code_by_addr(ip_addr)
        cc_name = gi.country_name_by_addr(ip_addr)
        return cc, cc_name

    def lookup_ipv6_address(self, ip_addr):
        print "Reverse lookup for: " + ip_addr
        split_addr = ip_addr.split(":")
        for i in ["RIR", "LIR"]:
            ip_query = ip_addr.split(":")[0] + ":" + ip_addr.split(":")[1] + "%"
            result = self.database_cache.rir_or_lir_lookup_ipv6(ip_addr, ip_query, i)
            if result:
                   print i, "Country Name:", self.get_name_from_country_code(result)
            else:
                ip_query = ip_addr.split(":")[0] + ":%"
                result = self.database_cache.rir_or_lir_lookup_ipv6(ip_addr, ip_query, i)
                if result:
                    print i, "Country Name:", self.get_name_from_country_code(result)



    def lookup_ip_address(self, ip_addr):
        """ Return the country code and name for a given ip address. Attempts to
            use GeoIP if available."""

        ip_addr = socket.getaddrinfo(ip_addr, 80)[0][4][0]
        if IPy and IPy.IP(ip_addr).version() == 6:
            self.database_cache.lookup_ipv6_address(ip_addr)
            return

        if not ipv4_address_valid(ip_addr):
            raise BlockFinderError('Invalid ip address!')
        print "Reverse lookup for: " + ip_addr
        if GeoIP:
            geoip_cc, geoip_cc_name = self.geoip_lookup(ip_addr)
            print "GeoIP country code: " + str(geoip_cc)
            print "GeoIP country name: " + str(geoip_cc_name)

        rir_cc = self.database_cache.rir_lookup(ip_addr)
        if rir_cc:
            print 'RIR country code:', rir_cc
            print 'RIR country:', self.get_name_from_country_code(rir_cc)
        else:
            print 'Not found in RIR db'

        lir_cc = self.database_cache.lir_lookup(ip_addr)
        if lir_cc:
            print 'LIR country code:', lir_cc
            print 'LIR country:', self.get_name_from_country_code(lir_cc)

        if GeoIP:
            if geoip_cc != rir_cc:
                print "It appears that the RIR data conflicts with the GeoIP data"
                print "The GeoIP data is likely closer to being correct due to " \
                      "sub-delegation issues with LIR databases"

    def asn_lookup(self, asn):
        asn_cc = self.database_cache.asn_lookup(asn)
        if asn_cc:
            print "AS country code: %s" % asn_cc
            print "AS country name: %s" % self.get_name_from_country_code(asn_cc)
        else:
            print "AS%s not found!" % asn

    def fetch_rir_blocks_by_country(self, request, country):
        return self.database_cache.use_sql_database(request, country)

def main():
    """ Where the magic starts. """

    parser = OptionParser()
    parser.add_option("-v", "--verbose", action="store_true", dest="verbose", \
            help = "Be verbose", default=False)

    parser.add_option("-c", "--cachedir", action="store", dest="cache_dir", \
            help = "Set the cache directory", default= str(os.path.expanduser('~')) + "/.blockfinder/" )

    parser.add_option("-u","--useragent", action="store", dest="user_agent", \
            help = "Provide a useragent which will be used when fetching delegation files" , \
            default="Mozilla/5.0")

    parser.add_option("-4", "--ipv4", action="store_true", dest="ipv4", \
            help = "Search IPv4 allocations")

    parser.add_option("-6", "--ipv6", action="store_true", dest="ipv6", \
            help = "Search IPv6 allocations")

    parser.add_option("-a", "--asn", action="store_true", dest="asn", \
            help = "Search ASN allocations")

    parser.add_option("-t", "--nation-state", action="store", dest="cc", \
            help = "Set the country to search (given as a two-letter code)")

    parser.add_option("-n", "--country-name", action="store", dest="country_name", \
            help = "Set country to search (full name)")

    parser.add_option("-x", "--hack-the-internet", action="store_true", dest="hack_the_internet", \
            help = "Hack the internet")

    parser.add_option("-r", "--reverse-lookup", action="store", dest="reverse_host", \
            help = "Return the country name for the specified IP or ASN or hostname")

    parser.add_option("-i", "--initialize-delegation", action="store_true", dest="init_del", \
            help = "Initialize or update delegation information")

    parser.add_option("-l", "--initialize-lir", action="store_true", dest="init_lir", \
            help = "Initialize or update lir information")

    parser.add_option("-d", "--reload-delegation", action="store_true", dest="reload_del", \
            help = "Use existing delegation files to update the database")

    parser.add_option("-z", "--reload-lir", action="store_true", dest="reload_lir", \
            help = "Use existing lir files to update the database")

    (options, args) = parser.parse_args()
    country = None
    verbose = options.verbose
    user_agent = options.user_agent
    cache_dir = options.cache_dir

    database_cache = DatabaseCache(cache_dir, verbose)
    database_cache.connect_to_database()
    downloader_parser = DownloaderParser(cache_dir, database_cache, user_agent)
    lookup = Lookup(cache_dir, database_cache)

    requests = []
    delegation_urls = """
        ftp://ftp.arin.net/pub/stats/arin/delegated-arin-latest
        ftp://ftp.ripe.net/ripe/stats/delegated-ripencc-latest
        ftp://ftp.afrinic.net/pub/stats/afrinic/delegated-afrinic-latest
        ftp://ftp.apnic.net/pub/stats/apnic/delegated-apnic-latest
        ftp://ftp.lacnic.net/pub/stats/lacnic/delegated-lacnic-latest
    """
    geoip_country_urls = """http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz
    http://geolite.maxmind.com/download/geoip/database/GeoIPv6.dat.gz"""

    lir_urls = """ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inetnum.gz
    ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inet6num.gz"""
    delegation_files = []
    for url in delegation_urls.split():
        filename = url.rpartition('/')
        delegation_files.append(filename[-1])

    downloader_parser.create_blockfinder_cache_dir()
    if not os.path.exists(cache_dir + "countrycodes.txt"):
        try:
            downloader_parser.download_country_code_file()
        except Exception, e:
            print repr(e)


    if options.hack_the_internet:
        print "all your bases are belong to us!"
        sys.exit(0)
    if options.asn and options.reverse_host:
        lookup.asn_lookup(options.reverse_host)
        sys.exit(0)

    if options.reverse_host:
        lookup.lookup_ip_address(options.reverse_host)
        sys.exit(0)

    if options.ipv4:
        requests.append("ipv4")
    if options.ipv6:
        requests.append("ipv6")
    if options.asn:
        requests.append("asn")

    if options.cc:
        country = options.cc.upper()
    if options.country_name:
        country = lookup.get_country_code_from_name(options.country_name)

    if options.reload_del:
        downloader_parser.create_db_and_insert_delegation_into_db(delegation_urls)
        sys.exit(0)

    # Update and quit.
    if options.init_del:
        if GeoIP:
            downloader_parser.update_geoip_cache(geoip_country_urls)
        downloader_parser.update_delegation_cache(delegation_urls)
        if verbose:
            lookup.verify_cache(delegation_files)
        downloader_parser.create_db_and_insert_delegation_into_db(delegation_urls)
        if not options.init_lir:
            sys.exit(0)
    if options.init_lir or options.reload_lir:
        if options.init_lir:
            downloader_parser.update_lir_delegation_cache(lir_urls)
        print "Extracting and inserting information from the lir files can take up to 5 minutes"
        database_cache.create_or_replace_lir_table_in_db()
        for fname in "ripe.db.inetnum ripe.db.inet6num".split():
            downloader_parser.extract_info_from_lir_file_and_insert_into_sqlite(fname)
        sys.exit(0)

    if not requests:
        print "Nothing to do. Have you requested anything?"
        print "Example usage: blockfinder -v --ipv4 -t mm"
        sys.exit(1)

    if not country:
        print "It appears your search did not match a country."
        sys.exit(1)
    # Check our cache age and warn if it's aged
    if downloader_parser.cache_is_dated(delegation_files) and verbose:
        print "Your delegation cache is older than 24 hours; you probably want to update it."
    if verbose:
        print "Using country code: %s" % country

    for request in requests:
        try:
            try:
                print " \n".join(lookup.fetch_rir_blocks_by_country(request, country))
            except sqlite3.Error, e:
                print repr(e)
                print "Please try reloading the database. (run ./blockfinder -i)."
        except Exception, e:
            print repr(e)
    try:
        database_cache.commit_and_close_database()
    except Exception, e:
        print repr(e)

if __name__ == "__main__":
    main()
