#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# For the people of Smubworld!
import urllib2
import os
import time
import getopt
import sys
from math import ceil, log
import sqlite3
import hashlib
import gzip
from xml.dom import minidom
import socket
__program__ = 'blockfinder'
__url__ = 'http://github.com/ioerror/blockfinder/'
___author__ = 'Jacob Appelbaum <jacob@appelbaum.net>, dave b. <db@d1b.org>'
__copyright__ = 'Copyright (c) 2010'
__license__ = 'See LICENSE for licensing information'
__version__ = '3.1415'

try:
    import GeoIP
except ImportError:
     GeoIP = None

try:
    from future import antigravity
except ImportError:
    antigravity = None

class BlockFinderError(Exception):
    pass

def update_progress_bar(percent_done, caption=""):
    """Write a progress bar to the console"""
    rows, columns = map(int, os.popen('stty size', 'r').read().split())
    width = columns - 4 - len(caption)
    sys.stdout.write("[%s>%s] %s\x1b[G" % (
                                    "=" * int(percent_done*width),
                                    "." * (width - int(percent_done * width)),
                                    caption) )
    sys.stdout.flush()

# XXX TODO:allow the use of a proxy
# Set up a proper Request object, set the user agent and if desired, a proxy
def fetch(url, useragent):
    """ Fetch (with progress meter) and return the contents of a url. """
    req = urllib2.Request(url)
    req.add_header('User-agent', useragent)
    #req.set_proxy(host, type)
    fetcher = urllib2.urlopen(req)
    length_header = fetcher.headers.get("content-length")
    if length_header == None:
        raise Exception("Missing content-length header in reply from server.")
    length = int(length_header)
    print "Fetching ", str (round(float(length/1024),2)) , " kilobytes"
    ret = ""
    t_start = time.time()
    while True:
        t_delta = time.time() - t_start
        if t_delta == 0:
            t_delta = 1
        update_progress_bar(
            float(len(ret)) / length,
            "%.2f K/s" % (len(ret) / 1024 / t_delta) )
        tmp = fetcher.read(1024)
        if len(tmp) == 0:
            if len(ret) != length:
                raise Exception("Expected %s bytes, only received %s" % (
                                len(ret), length ))
            print ""
            return ret
        ret += tmp

def create_blockfinder_cache_dir(cache_dir):
    if not os.path.exists(cache_dir):
        if verbose:
            print "Initializing the cache directory..."
        os.mkdir(cache_dir)

def write_to_a_text_file(file_loc, data):
    f = open(file_loc, 'w')
    f.write(data)
    f.close()

def cache_delegation(cache_dir, delegation_url, useragent):
    """ Attempt to cache the contents of a delegation url in our cache dir. """
    delegation = ""
    print "Fetching " + delegation_url
    delegation = fetch(delegation_url,useragent)
    tmp = delegation_url.split('/')
    delegation_file = str(cache_dir) + str(tmp[-1])
    try:
        write_to_a_text_file(delegation_file, delegation)
        return True
    except Exception, e:
        print repr(e)
        return False

def cache_is_dated(cache_dir, cached_files):
    """ Returns True if the mtime of any files in cache dir is > 24hrs."""
    try:
        os.stat(cache_dir)
    except OSError, e:
        print "\nDid you initialize the cache directory?\n"
        raise e
    for file in cached_files:
        fstat = os.stat(cache_dir + file)
        if (time.time() - fstat.st_mtime) > 86400:
            return True
    return False

def create_sql_database(cache_dir):
    """ Creates a new sqlite database.
         If there is a previous sqlite database it will be deleted. """
    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor = conn.cursor()
    for table in ["ipv4", "ipv6", "asn"]:
        cursor.execute("""drop table if exists """ + table)
    cursor.execute("""create table asn(registry text, cc text, start text, value INTEGER, date text, status text)""")
    cursor.execute("""create table ipv4(registry text, cc text, start text, value INTEGER, date text, status text)""")
    cursor.execute("""create table ipv6(registry text, cc text, start text, value INTEGER, date text, status text)""")
    cursor.execute("""create table if not exists lir_record(cc text, start text, value INTEGER, type INTEGER)""")
    conn.commit()
    cursor.close()

def insert_into_sql_database(delegations,cache_dir):
    """ inserts delegation information into the sqlite database"""
    conn = sqlite3.connect(cache_dir +"sqlitedb")
    cursor = conn.cursor()
    table = ""
    for delegation in delegations:
        for entry in delegation:
            registry = str(entry['registry'])
            if not registry.isdigit() and str (entry['cc']) !="*":
                if entry['type'] == "ipv6":
                    table = "ipv6"
                if entry['type'] == "ipv4":
                    table = "ipv4"
                if entry['type'] == "asn":
                    table = "asn"
                text = """INSERT INTO """ + table + """ ( registry, cc, start, value, date,status) VALUES (?,?,?,?,?,?)"""
                data = [entry['registry'], entry['cc'], entry['start'], entry['value'], entry['date'], entry['status'] ]
                cursor.execute(text, data  )
    conn.commit()
    cursor.close()

def get_total_delegations_from_db(cache_dir):
    """ Returns the total count of the number of entries in the ipv4, ipv6 and asn table """
    conn = sqlite3.connect(cache_dir +"sqlitedb")
    cursor = conn.cursor()
    count = 0
    table_names = ["ipv4", "ipv6", "asn"]
    for table in table_names:
        cursor.execute("""select count (*)  from """ + table)
        count += int (cursor.fetchone()[0] )
    cursor.close()
    return count

def get_possible_match_entries(cc,cache_dir):
    """ Get the count of 'possible' matching delegation entries"""
    conn = sqlite3.connect(cache_dir +"sqlitedb")
    cursor = conn.cursor()
    count = 0
    table_names =["ipv4", "ipv6", "asn"]
    for table in table_names:
        cursor.execute("""select count (*)  from """ + table + """ where cc=?""",cc)
        count += int (cursor.fetchone()[0] )
    cursor.close()
    return count

def use_sql_database(request, cc, cache_dir):
    """ Use the sqlite database that is created after fetching delegations
        to output information for a given request """
    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor = conn.cursor()
    if verbose:
        print "We have %d entries in our delegation cache." %get_total_delegations_from_db(cache_dir)
    text ="""select start,value from """ + request + """ where cc=?"""
    cc = (cc,)
    cursor.execute(text,cc)
    result = []
    for row in cursor:
        if request == "ipv4":
            result.append(str(row[0]) + "/" + str(calculate_ipv4_subnet(int(row[1]))))
        elif request == "ipv6":
            result.append(str(row[0]) + "/" + str(int(row[1])))
        else:
            result.append(str(int(row[0])))
    if verbose:
        print "We found %d possible entries in our delegation cache." % get_possible_match_entries(cc, cache_dir)
        cursor.execute("""select count(*) from """ + request + """ where cc=?""", cc )
        print "We found %d matching entries in our delegation cache." % int (cursor.fetchone()[0] )
    cursor.close()
    return result

def get_md5_from_delegation_md5_file(cache_dir, delegation_file):
    """ Returns the md5sum from the delegation md5 file
        if it doesn't exist it returns an empty string"""
    checksum = ""
    try:
        f = open(cache_dir + delegation_file + ".md5", "r")
        checksum = f.read()
        f.close()
        if delegation_file == "delegated-afrinic-latest":
            pos =  checksum.find(" ")
            checksum = str (checksum[:pos])
        else:
            pos = checksum.find("=") +2
            checksum = str (checksum[pos:-1])
    except Exception, e:
        print repr(e)
    return checksum

def verify_delegation_file(cache_dir, delegation_file):
    """ compares the delegation file md5sum to that of the provided md5sum
       returns True if they match otherwise returns False """
    checksum = ""
    checksum_of_file = ""
    try:
        f = open(cache_dir + delegation_file, "rb")
        checksum_of_file = str (hashlib.md5(f.read()).hexdigest() )
        f.close()
    except Exception, e:
        print repr(e)
    checksum = get_md5_from_delegation_md5_file(cache_dir,delegation_file)
    if checksum != checksum_of_file:
        return False
    if checksum == checksum_of_file and checksum != "":
        return True
    return False

def verify_cache(cache_dir, delegation_files):
    """ if in verbose mode prints the result of checking the checksum of the
        delegation files """
    for file in delegation_files:
        if verbose:
            print "verifying " + file
        if verify_delegation_file(cache_dir,file):
            if verbose:
                print "the md5 checksum of " + file + " *matches* the provided checksum"
        else:
            if verbose:
                print "the md5 checksum of " + file + " does *not* match the provided checksum"

def update_delegation_cache(cache_dir, delegation_urls, useragent):
    """ Fetch multiple delegation urls and cache the contents. """
    print "Updating delegation cache..."

    for url in delegation_urls.split():
        cache_delegation(cache_dir, url + ".md5",useragent)
        if verify_delegation_file(cache_dir, url.rpartition('/')[-1]):
            pass
        else:
            cache_delegation(cache_dir, url,useragent)

def update_lir_delegation_cache(cache_dir, delegation_urls, useragent):
    """ Fetch multiple LIR delegation urls and cache the contents. """
    print "Updating LIR delegation cache..."
    for url in delegation_urls.split():
        cache_delegation(cache_dir, url,useragent)
    unpack_a_delegation_cache(cache_dir, delegation_urls, "LIR")


def extract_data_from_gzip_file(gzip_file_loc, extract_file_loc):
        gzip_file = gzip.open(gzip_file_loc, 'rb')
        gunzipped_data = gzip_file.read()
        gzip_file.close()
        gunzipped_file = open(extract_file_loc, 'w')
        gunzipped_file.writelines(gunzipped_data)
        gunzipped_file.close()

def unpack_a_delegation_cache(cache_dir, delegation_urls, del_type=""):
    """ Unpack the fetched LIR delegation files into the blockfinder cache. """
    # This probably should unlink the gzip'ed file if we care about space...
    for url in delegation_urls.split():
        gzip_filename = url.rpartition('/')[-1]
        gunziped_filename = gzip_filename.rpartition('.')[0]
        if verbose:
            print "Unpacking " + del_type + "file " + gzip_filename + " into our cache as " + gunziped_filename
        extract_data_from_gzip_file(cache_dir + gzip_filename, cache_dir + gunziped_filename)

def update_geoip_cache(cache_dir, geoip_urls, useragent):
    """ Fetch country level resolution GeoIP files from a given url and cache
    the contents. Unpack it if it's compressed. """
    print "Updating GeoIP cache..."
    for url in geoip_urls.split():
        cache_delegation(cache_dir, url, useragent)
    unpack_a_delegation_cache(cache_dir, geoip_urls, "GeoIP")

def load_delegation(delegation_file):
    """ Load, parse and store the delegation file contents as a list. """
    keys = "registry cc type start value date status"
    try:
        f = open(delegation_file, "r")
        delegations = [ dict((k,v) for k,v in zip(keys.split(), line.split("|")))
                        for line in f.readlines() if not line.startswith("#")]
        f.close()
        return delegations
    except OSError, e:
        print repr(e)

def load_all_delegations(cache_dir, delegation_urls):
    """ Load all delegations into memory. """
    delegations = []
    for url in delegation_urls.split():
        filename = url.rpartition('/')[-1]
        if verbose:
            print "Attempting to load delegation file into memory: " + filename
        delegations.append(load_delegation(cache_dir + filename))
    return delegations

def calculate_ipv4_subnet(host_count):
    return 32 - int(ceil(log(host_count,2)))

def download_country_code_file(cache_dir, useragent):
    """ Download and save the latest opencountrycode XML file """
    # Google frontend will not return content-length for some reason...
    url = "http://opencountrycodes.appspot.com/xml"
    xml = urllib2.urlopen(url).read()
    write_to_a_text_file(cache_dir + "countrycodes.xml", xml)

def build_country_code_dictionary(cache_dir):
    """ Return a dictionary mapping country name to the country code"""
    map_co = {}
    xml_file = str(cache_dir) + "countrycodes.xml"
    clist = minidom.parse(xml_file)
    for country in clist.getElementsByTagName("country"):
        code = country.attributes["code"]
        name = country.attributes["name"]
        map_co[name.value] = code.value
    return map_co

def get_name_from_country_code(cache_dir, cc_code):
    map_co = build_country_code_dictionary(cache_dir)
    country_name = [(key, value) for (key, value) in map_co.items() if value == cc_code]
    if len(country_name) > 0:
        return country_name[0][0]

def get_country_code_from_name(cache_dir, country_name):
    """ Return the country code for a given country name. """
    map_co = build_country_code_dictionary(cache_dir)
    cc_code = [map_co[key] for key in map_co.keys() if key.upper().startswith(country_name.upper())]
    if len(cc_code) > 0:
        return cc_code[0]

def ip_address_to_dec(ip_addr):
    ipar = ip_addr.split('.')
    a = ['','','','']
    for i in range(4):
        a[i] = hex(int(ipar[i]))[2:]
        if(int(ipar[i]) <= 15):
            a[i] = """0""" + a[i]

    total = '0x'+a[0]+a[1]+a[2]+a[3]
    decimal = int(total,16)
    return decimal

def ipv4_address_valid(ip_addr):
    ipv4arr = ip_addr.split('.')
    if len(ipv4arr) == 4:
        for items in ipv4arr:
            if int(items) > 255:
                return False
        return True
    else:
        return False

def geoip_lookup(cache_dir, ip_addr):
    # This would work with the CVS version of the GeoIP code
    # However, MaxMind hasn't done a release in a long time.
    # http://geoip.cvs.sourceforge.net/viewvc/geoip/python/test_v6.py?revision=1.1&view=markup
    #        gi = GeoIP.open(cache_dir + "GeoIPv6.dat",GeoIP.GEOIP_STANDARD)
    #        cc = gi.country_code_by_addr_v6(ip_addr)
    #        cc_name = gi.country_name_by_addr_v6(ip_addr)
    gi = GeoIP.open(cache_dir + "GeoIP.dat",GeoIP.GEOIP_STANDARD)
    cc = gi.country_code_by_addr(ip_addr)
    cc_name = gi.country_name_by_addr(ip_addr)
    return cc, cc_name

def rir_lookup(ip_addr, cache_dir):
    ipv4arr = ip_addr.split('.')
    result = []

    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor = conn.cursor()

    cursor.execute('select * from ipv4 WHERE start LIKE ?', ( ipv4arr[0] + "." + ipv4arr[1] + ".%",))
    row = cursor.fetchone()
    if row is None:
        cursor.execute('select * from ipv4 WHERE start LIKE ?', ( ipv4arr[0] + ".%",))
        row = cursor.fetchone()

    while(row is not None):
        if(ip_address_to_dec(row[2]) <= ip_address_to_dec(ip_addr) < (ip_address_to_dec(row[2])+row[
3])):
            rir_cc = row[1]
            rir_cc_name = get_name_from_country_code(cache_dir, row[1])
            result.append(rir_cc)
            result.append(rir_cc_name)
            return result
        row = cursor.fetchone()
    cursor.close()
    return 1

def lir_lookup(ip_addr, cache_dir):
    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor = conn.cursor()

    ipv4arr = ip_addr.split('.')
    result = []

    cursor.execute('select * from lir_record WHERE start LIKE ? and type=4', (ipv4arr[0] + "." + ipv4arr[1] + ".%",))
    row = cursor.fetchone()
    if row is None:
        cursor.execute('select * from lir_record WHERE start LIKE ? and type=4', (ipv4arr[0] + ".%",))
        row = cursor.fetchone()


    while(row is not None):
        if (ip_address_to_dec(row[1]) <= ip_address_to_dec(ip_addr) <= (ip_address_to_dec(row[1]) + row[2])):
            result.append(row[0])
            result.append(get_name_from_country_code(cache_dir, row[0]))
            return result
        row = cursor.fetchone()
    cursor.close()
    return 1

def lookup_ip_address(ip_addr, cache_dir):
    """ Return the country code and name for a given ip address. Attempts to
        use GeoIP if available."""

    ip_addr = socket.gethostbyname(ip_addr)
    if not ipv4_address_valid(ip_addr):
        raise BlockFinderError('Invalid ip address!')
    rir_cc = ""
    print "Reverse lookup for: " + ip_addr
    if GeoIP:
        geoip_cc, geoip_cc_name = geoip_lookup(cache_dir, ip_addr)
        print "GeoIP country code: " + str(geoip_cc)
        print "GeoIP country name: " + str(geoip_cc_name)

    ipv4arr = ip_addr.split('.')
    if len(ipv4arr) != 4:
       print """doesn't look like an ipv4 address.."""
       sys.exit(5)
    rir = rir_lookup(ip_addr, cache_dir)

    if(rir != 1):
        print 'RIR country code:', rir[0]
        print 'RIR country:', rir[1]
    else:
        print 'Not found in RIR db'

    lir = lir_lookup(ip_addr, cache_dir)
    if(lir != 1):
        print 'LIR country code:', lir[0]
        print 'LIR country :', lir[1]

    if GeoIP:
        if geoip_cc != rir_cc:
            print "It appears that the RIR data conflicts with the GeoIP data"
            print "The GeoIP data is likely closer to being correct due to " \
                  "sub-delegation issues with LIR databases"

def return_first_ip_and_number_in_inetnum(line):
    start_ip = line.split("-")[0].strip()
    end_ip = line.split("-")[1].strip()
    num_ips = 1 + (ip_address_to_dec(end_ip) - ip_address_to_dec(start_ip) )
    return start_ip, num_ips

def create_or_replace_lir_table_in_db(cache_dir):
    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor = conn.cursor()
    cursor.execute("""drop table if exists lir_record """)
    cursor.execute("""create table if not exists lir_record(cc text, start text, value INTEGER, type INTEGER)""")
    conn.commit()
    cursor.close()

def extract_info_from_lir_file_and_insert_into_sqlite(cache_dir, filename):
    block = []
    country = ""
    entry = False
    conn = sqlite3.connect(cache_dir + "sqlitedb")
    cursor =  conn.cursor()
    insert_text = """insert into lir_record (cc, start, value, type) VALUES (?,?,?,?)"""
    version = ""
    for line in open(cache_dir + filename, "r"):
        line = line.replace("\n", "")
        if line == "":
            entry = False
            country, block, version = "", [], ""
        elif not entry and "inetnum:" in line:
            try:
                line = line.replace("inetnum:", "").strip()
                start_ip, num_ips = return_first_ip_and_number_in_inetnum(line)
                block = [start_ip, num_ips]
                entry = True
                version = "4"
            except Exception, e:
                print e
        elif not entry and "inet6num:" in line:
            try:
                block = line.replace("inet6num:", "").strip().split("/")
                entry = True
                version = "6"
            except Exception, e:
                print e
        elif entry and "country:" in line:
            country = line.replace("country:", "").strip()
            data = (country, block[0], block[1], version )
            cursor.execute(insert_text, data)
    conn.commit()
    cursor.close()

def create_db_and_insert_delegation_into_db(cache_dir, delegation_urls):
        create_sql_database(cache_dir)
        delegations = load_all_delegations(cache_dir, delegation_urls)
        insert_into_sql_database(delegations, cache_dir)


def usage():
    """ Print usage information. """
    print >> sys.stderr, """
blockfinder  [-c DIR] -i
blockfinder [options] -t COUNTRY

The first form initializes the local cache. The second form queries it.

Understood options (not all of which are implemented yet):
    -h, --help          Show this help and exit
    -v                  Be verbose
    -c, --cachedir DIR  Set the cache directory
    -u, --useragent
    -p, --progress
    -o, --output FILE
    -4, --ipv4          Search IPv4 allocations
    -6, --ipv6          Search IPv6 allocation
    -a, --asn           Search ASN allocations
    -t, --nation-state CC  Set the country to search (given as a two-letter code)
    -n, --country-name "Costa Rica"  Set country to search (full name)
    -x, --hack-the-internet          Hack the internet
    -r, --reverse-lookup    Return the county name for the specified IP
    -i, --initialize-delegation    Initialize or update delegation information
    -l, --initialize-lir    Initialize or update lir information
    -d, --reload-delegation    Use existing delegation files to update the database

At least one of -t or -i is required, and when in -t mode, at least one of -4,
-6, and -a is required in order to do anything sensible.
"""

def main():
    """ Where the magic starts. """
    try:
        opts, args = getopt.getopt(sys.argv[1:], "dlxvhc:u:pso:46at:n:ir:",
                                   ["reload-delegation", "initialize-lir", "hack-the-internet",
                                   "verbose", "help", "cachedir=", "useragent=", "progress",
                                   "silent", "output=", "ipv4", "ipv6","asn", "nation-state=",
                                   "country-name", "initialize-delegation","reverse-lookup"])
    except getopt.GetoptError, err:
        print str(err)
        usage()
        sys.exit(2)

    global verbose
    verbose = False
    output = None
    silent = True
    cache_dir = str(os.path.expanduser('~')) + "/.blockfinder/"
    update_delegations = False
    delegation_urls = """
        ftp://ftp.arin.net/pub/stats/arin/delegated-arin-latest
        ftp://ftp.ripe.net/ripe/stats/delegated-ripencc-latest
        ftp://ftp.afrinic.net/pub/stats/afrinic/delegated-afrinic-latest
        ftp://ftp.apnic.net/pub/stats/apnic/delegated-apnic-latest
        ftp://ftp.lacnic.net/pub/stats/lacnic/delegated-lacnic-latest
    """
    geoip_country_urls = """http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz
    http://geolite.maxmind.com/download/geoip/database/GeoIPv6.dat.gz"""

    lir_urls = """ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inetnum.gz
    ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inet6num.gz"""
    delegation_files = []
    for url in delegation_urls.split():
        filename = url.rpartition('/')
        delegation_files.append(filename[-1])
    update_delegations = False
    update_lir = False
    reload_delegation_db = False
    requests = []
    country = ""
    useragent = "Mozilla/5.0"
    ipaddress = ""

    create_blockfinder_cache_dir(cache_dir)
    if not os.path.exists(cache_dir + "countrycodes.xml"):
        try:
            download_country_code_file(cache_dir,useragent)
        except Exception, e:
            print repr(e)

    for o, a in opts:
        if o in ("-x", "--hack-the-internet"):
            print "all your bases are belong to us!"
            sys.exit(4)
        if o == "-v":
            verbose = True
        elif o in ("-h", "--help"):
            usage()
            sys.exit()
        elif o in ("-c", "--cachedir"):
            cache_dir = a
        elif o in ("-u", "--useragent"):
            useragent = a
        elif o in ("-p", "--progress"):
            progress = True
        elif o in ("-s", "--silent"):
            silent = True
        elif o in ("-o", "--output"):
            output = a
        elif o in ("-4", "--ipv4"):
            requests.append("ipv4")
        elif o in ("-6", "--ipv6"):
            requests.append("ipv6")
        elif o in ("-a", "--asn"):
            requests.append("asn")
        # XXX TODO: This should be a positional argument as it's the only manditory one...
        elif o in ("-r", "--reverse-lookup"):
            ipaddress = a
            requests.append("reverse")
        elif o in ("-t", "--nation-state"):
            country = a.upper()
        elif o in ("-n", "--country-name"):
            country = get_country_code_from_name(cache_dir, a)
        elif o in ("-i", "--initialize-delegations"):
            update_delegations = True
        elif o in ("-l", "--initialize-lir"):
            update_lir = True
        elif o in ("-d", "--reload-delegation"):
            reload_delegation_db = True
        else:
            print "Unhandled option; Sorry!"
            sys.exit(3)

    if reload_delegation_db:
        create_db_and_insert_delegation_into_db(cache_dir, delegation_urls)
        sys.exit(0)

    # Update and quit.
    if update_delegations:
        if GeoIP:
            update_geoip_cache(cache_dir,geoip_country_urls,useragent)
        update_delegation_cache(cache_dir,delegation_urls,useragent)
        if verbose:
            verify_cache(cache_dir, delegation_files)
        create_db_and_insert_delegation_into_db(cache_dir, delegation_urls)
        if not update_lir:
            sys.exit(0)
    if update_lir:
        update_lir_delegation_cache(cache_dir,lir_urls,useragent)
        print "Extracting and inserting information from the lir files can take up to 5 minutes"
        create_or_replace_lir_table_in_db(cache_dir)
        for file in "ripe.db.inetnum ripe.db.inet6num".split():
            extract_info_from_lir_file_and_insert_into_sqlite(cache_dir, file)
        sys.exit(0)

    if not requests:
        print "Nothing to do. Have you requested anything?"
        print "Example usage: blockfinder -v --ipv4 -t mm"
        sys.exit(1)

    if ipaddress:
        lookup_ip_address(ipaddress,cache_dir)
        sys.exit(0)
    if not country:
        print "It appears your search did not match a country."
        sys.exit(1)
    # Check our cache age and warn if it's aged
    if cache_is_dated(cache_dir, delegation_files) and verbose:
        print "Your delegation cache is older than 24 hours; you probably want to update it."
    if verbose:
        print "Using country code: %s" % country

    for request in requests:
        try:
            print " \n".join(use_sql_database(request, country, cache_dir))
        except Exception, e:
            print repr(e)

if __name__ == "__main__":
    main()
