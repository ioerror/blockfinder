#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# For the people of Smubworld!
import urllib2
import os
import time
import optparse
import sys
import sqlite3
import hashlib
import gzip
import ipaddr
__program__ = 'blockfinder'
__url__ = 'https://github.com/ioerror/blockfinder/'
__author__ = 'Jacob Appelbaum <jacob@appelbaum.net>, David <db@d1b.org>'
__copyright__ = 'Copyright (c) 2010'
__license__ = 'See LICENSE for licensing information'
__version__ = '3.1415'

try:
    import GeoIP
except ImportError:
     GeoIP = None

try:
    from future import antigravity
except ImportError:
    antigravity = None

class DatabaseCache:
    def __init__(self, cache_dir, verbose=False):
        self.cache_dir = cache_dir
        self.verbose = verbose
        self.cursor = None
        self.conn = None

    def connect_to_database(self):
        if not os.path.exists(self.cache_dir):
            if self.verbose:
                print "Initializing the cache directory..."
            os.mkdir(self.cache_dir)
        self.conn = sqlite3.connect(self.cache_dir + "sqlitedb")
        self.cursor = self.conn.cursor()

    def commit_and_close_database(self):
        self.conn.commit()
        self.cursor.close()

    def create_sql_database(self):
        """ Creates a new sqlite database.
            Existing delegation entries are dropped prior to inserting
            'newer' delegations. """
        sql = ('DROP TABLE IF EXISTS delegations; '
               'CREATE TABLE delegations(registry TEXT, cc TEXT, '
               'start TEXT, value INTEGER, date TEXT, status TEXT, '
               'type TEXT); '
               'CREATE TABLE IF NOT EXISTS lir_record(cc TEXT, '
               'start TEXT, value INTEGER, type INTEGER)')
        self.cursor.executescript(sql)
        self.conn.commit()

    def insert_into_sql_database(self, rows):
        """ Inserts delegation information into the sqlite database. """
        sql = ('INSERT INTO delegations (registry, cc, start, value, '
               'date, status, type) VALUES (?, ?, ?, ?, ?, ?, ?)')
        self.cursor.executemany(sql, rows)
        self.conn.commit()

    def _get_total_delegations_from_db(self):
        """ Returns the total count of the number of entries in the ipv4,
            ipv6 and asn table. """
        sql = 'SELECT COUNT(*) FROM delegations'
        self.cursor.execute(sql)
        return int(self.cursor.fetchone()[0])

    def _get_possible_match_entries(self, cc):
        """ Get the count of 'possible' matching delegation entries. """
        sql = 'SELECT COUNT(*) FROM delegations WHERE cc = ?'
        self.cursor.execute(sql, cc)
        return int(self.cursor.fetchone()[0])

    def use_sql_database(self, request, cc):
        """ Use the sqlite database that is created after fetching
            delegations to output information for a given request. """
        if self.verbose:
            print "We have %d entries in our delegation cache." % \
                    self._get_total_delegations_from_db()
        sql = ('SELECT start, value FROM delegations WHERE type = ? '
               'AND cc = ?')
        cc = (cc,)
        self.cursor.execute(sql, (request, cc[0]))
        result = []
        for row in self.cursor:
            if request == "ipv4":
                start_ipaddr = ipaddr.IPv4Address(str(row[0]))
                end_ipaddr = start_ipaddr + int(row[1]) - 1
                result += [str(x) for x in \
                        ipaddr.summarize_address_range( \
                        start_ipaddr, end_ipaddr)]
            elif request == "ipv6":
                result.append(str(row[0]) + "/" + str(int(row[1])))
            else:
                result.append(str(int(row[0])))
        result.sort()
        if self.verbose:
            result.append("We found %d possible entries in our "
                  "delegation cache." % \
                  self._get_possible_match_entries(cc))
            sql = ('SELECT COUNT(*) FROM delegations WHERE cc = ? '
                   'AND type = ?')
            self.cursor.execute(sql, (cc[0], request))
            result.append("We found %d matching entries in our "
                    "delegation cache." % int(self.cursor.fetchone()[0]))
        return result

    def _rir_or_lir_lookup_ipv4(self, ip_addr, lookup_type):
        ipv4arr = ip_addr.split('.')
        if lookup_type == 'rir':
            sql = ('SELECT cc, start, value FROM delegations '
                   'WHERE type = "ipv4" AND start LIKE ?')
            self.cursor.execute(sql,
                    (ipv4arr[0] + "." + ipv4arr[1] + ".%",))
        else:
            sql = ('SELECT cc, start, value FROM lir_record '
                   'WHERE start LIKE ? AND type = 4')
            self.cursor.execute(sql,
                    (ipv4arr[0] + "." + ipv4arr[1] + ".%",))
        row = self.cursor.fetchone()
        if row is None:
            if lookup_type == "rir":
                sql = ('SELECT cc, start, value FROM delegations '
                       'WHERE type = "ipv4" AND start LIKE ?')
                self.cursor.execute(sql, (ipv4arr[0] + ".%",))
            else:
                sql = ('SELECT cc, start, value FROM lir_record '
                       'WHERE start LIKE ? AND type = 4')
                self.cursor.execute(sql, (ipv4arr[0] + ".%",))
            row = self.cursor.fetchone()
        lookup_ipaddr = ipaddr.IPv4Address(ip_addr)
        while row is not None:
            start_ipaddr = ipaddr.IPv4Address(str(row[1]))
            end_ipaddr = start_ipaddr + int(row[2]) - 1
            if start_ipaddr <= lookup_ipaddr and \
                    lookup_ipaddr <= end_ipaddr:
                return row[0]
            row = self.cursor.fetchone()

    def rir_lookup(self, ip_addr):
        return self._rir_or_lir_lookup_ipv4(ip_addr, "rir")

    def lir_lookup(self, ip_addr):
        return self._rir_or_lir_lookup_ipv4(ip_addr, "lir")

    def asn_lookup(self, asn):
        sql = ('SELECT cc FROM delegations WHERE type = "asn" AND '
               'start LIKE ?')
        self.cursor.execute(sql, (asn,))
        row = self.cursor.fetchone()
        if row:
            return row[0]

    def rir_or_lir_lookup_ipv6(self, ip_addr, ip_query, type_q):
        if type_q == "RIR":
            sql = ('SELECT cc, start, value FROM delegations '
                   'WHERE type = "ipv6" AND start like ?')
            self.cursor.execute(sql, (ip_query,))
        else:
            sql = ('SELECT cc, start, value FROM lir_record '
                   'WHERE type = 6 AND start LIKE ?')
            self.cursor.execute(sql, (ip_query,))
        lookup_ipaddr = ipaddr.IPv6Address(ip_addr)
        for row in self.cursor:
            network = ipaddr.IPv6Network(row[1] + "/" + str(row[2]))
            if lookup_ipaddr in network:
                return row[0]

    def create_or_replace_lir_table_in_db(self):
        sql = 'DROP TABLE IF EXISTS lir_record'
        self.cursor.execute(sql)
        sql = ('CREATE TABLE IF NOT EXISTS lir_record(cc TEXT, '
               'start TEXT, value INTEGER, type INTEGER)')
        self.cursor.execute(sql)
        self.conn.commit()

    def insert_lir_delegation(self, data):
        sql = ('INSERT INTO lir_record (cc, start, value, type) '
               'VALUES (?, ?, ?, ?)')
        self.cursor.execute(sql, data)
        self.conn.commit()

class DownloaderParser:
    def __init__(self, cache_dir, database_cache, user_agent, \
            verbose=False):
        self.cache_dir = cache_dir
        self.database_cache = database_cache
        self.user_agent = user_agent
        self.verbose = verbose

    def update_progress_bar(self, percent_done, caption=""):
        """Write a progress bar to the console"""
        rows, columns = map(int, \
                os.popen('stty size', 'r').read().split())
        width = columns - 4 - len(caption)
        sys.stdout.write("[%s>%s] %s\x1b[G" % (
                "=" * int(percent_done*width),
                "." * (width - int(percent_done * width)), caption))
        sys.stdout.flush()

    # XXX TODO:allow the use of a proxy
    # Set up a proper Request object, set the user agent and if desired,
    # a proxy
    def fetch(self, url):
        """ Fetch (with progress meter) and return the contents of a
            url. """
        req = urllib2.Request(url)
        req.add_header('User-Agent', self.user_agent)
        #req.set_proxy(host, type)
        fetcher = urllib2.urlopen(req)
        length_header = fetcher.headers.get("Content-Length")
        if length_header == None:
            """ The server did not provide a Content-Length header. """
            length_header = -1
        length = int(length_header)
        print "Fetching ", str(round(float(length/1024),2)), " kilobytes"
        ret = ""
        t_start = time.time()
        while True:
            t_delta = time.time() - t_start
            if t_delta == 0:
                t_delta = 1
            if length_header != -1:
                self.update_progress_bar(float(len(ret)) / length,
                    "%.2f K/s" % (len(ret) / 1024 / t_delta))
            tmp = fetcher.read(1024)
            if len(tmp) == 0:
                if len(ret) != length and length_header != -1:
                    raise Exception("Expected %s bytes, only received " \
                            "%s" % (len(ret), length))
                print ""
                return ret
            ret += tmp

    def write_to_a_text_file(self, file_loc, data):
        f = open(file_loc, 'w')
        f.write(data)
        f.close()

    def extract_data_from_gzip_file(self, gzip_file_loc, \
                extract_file_loc):
        gzip_file = gzip.open(gzip_file_loc, 'rb')
        gunzipped_file = open(extract_file_loc, 'w')
        while True:
            gunzipped_data = gzip_file.read(1024)
            if gunzipped_data == "":
                break
            gunzipped_file.writelines(gunzipped_data)
        gzip_file.close()
        gunzipped_file.close()

    def read_data_from_binary_file(self, fname):
        f = open(fname, 'rb')
        data = f.read()
        f.close()
        return data

    def create_blockfinder_cache_dir(self):
        if not os.path.exists(self.cache_dir):
            if self.verbose:
                print "Initializing the cache directory..."
            os.mkdir(self.cache_dir)

    def cache_delegation(self, delegation_url):
        """ Attempt to cache the contents of a delegation url in our
            cache dir. """
        delegation = ""
        print "Fetching " + delegation_url
        delegation = self.fetch(delegation_url)
        tmp = delegation_url.split('/')
        delegation_file = str(self.cache_dir) + str(tmp[-1])
        try:
            self.write_to_a_text_file(delegation_file, delegation)
            return True
        except Exception, e:
            print repr(e)
            return False

    def cache_is_dated(self, cached_files):
        """ Returns True if the mtime of any files in cache dir is
            > 24 hours. """
        try:
            os.stat(self.cache_dir)
        except OSError, e:
            print "\nDid you initialize the cache directory?\n"
            raise e
        for file in cached_files:
            fstat = os.stat(self.cache_dir + file)
            if (time.time() - fstat.st_mtime) > 86400:
                return True
        return False

    def get_md5_from_delegation_md5_file(self, delegation_file):
        """ Returns the md5sum from the delegation md5 file
            if it doesn't exist it returns an empty string"""
        checksum = ""
        try:
            f = open(self.cache_dir + delegation_file + ".md5", "r")
            checksum = f.read()
            f.close()
            if "=" in checksum:
                pos = checksum.find("=") +2
                checksum = str(checksum[pos:-1])
        except Exception, e:
            print repr(e)
        return checksum

    def verify_delegation_file(self, delegation_file):
        """ Compares the delegation file md5sum to that of the provided
            md5sum, returns True if they match otherwise returns
            False. """
        checksum = ""
        checksum_of_file = ""
        try:
            data = self.read_data_from_binary_file(self.cache_dir + \
                    delegation_file)
            checksum_of_file = str(hashlib.md5(data).hexdigest())
        except Exception, e:
            print repr(e)
        checksum = self.get_md5_from_delegation_md5_file(delegation_file)
        if checksum != checksum_of_file:
            return False
        if checksum == checksum_of_file and checksum != "":
            return True
        return False

    def verify_cache(self, delegation_files):
        """ If in verbose mode prints the result of checking the checksum
            of the delegation files. """
        for file in delegation_files:
            if self.verbose:
                print "verifying " + file
            if self.verify_delegation_file(file):
                if self.verbose:
                    print "the md5 checksum of " + file + \
                            " *matches* the provided checksum"
            else:
                if self.verbose:
                    print "the md5 checksum of " + file + \
                            " does *not* match the provided checksum"

    def update_delegation_cache(self, delegation_urls):
        """ Fetch multiple delegation urls and cache the contents. """
        print "Updating delegation cache..."
        for url in delegation_urls.split():
            self.cache_delegation(url + ".md5")
            if self.verify_delegation_file(url.rpartition('/')[-1]):
                pass
            else:
                self.cache_delegation(url)

    def update_lir_delegation_cache(self, delegation_urls):
        """ Fetch multiple LIR delegation urls and cache the contents. """
        print "Updating LIR delegation cache..."
        for url in delegation_urls.split():
            self.cache_delegation(url)
        self.unpack_a_delegation_cache(delegation_urls, "LIR")

    def unpack_a_delegation_cache(self, delegation_urls, del_type=""):
        """ Unpack the fetched LIR delegation files into the blockfinder
            cache. """
        # This probably should unlink the gzip'ed file if we care about
        # space...
        for url in delegation_urls.split():
            gzip_filename = url.rpartition('/')[-1]
            gunziped_filename = gzip_filename.rpartition('.')[0]
            if self.verbose:
                print "Unpacking " + del_type + "file " + \
                        gzip_filename + " into our cache as " + \
                        gunziped_filename
            self.extract_data_from_gzip_file(self.cache_dir + \
                    gzip_filename, self.cache_dir + gunziped_filename)

    def update_geoip_cache(self, geoip_urls):
        """ Fetch country level resolution GeoIP files from a given url
            and cache the contents. Unpack it if it's compressed. """
        print "Updating GeoIP cache..."
        for url in geoip_urls.split():
            self.cache_delegation(url)
        self.unpack_a_delegation_cache(geoip_urls, "GeoIP")

    def load_delegation(self, delegation_file):
        """ Load, parse and store the delegation file contents as a
            list. """
        keys = "registry cc type start value date status"
        try:
            f = open(delegation_file, "r")
            delegations = [dict((k,v) for k,v in zip(keys.split(), \
                    line.strip().split("|"))) \
                    for line in f.readlines() if not line.startswith("#")]
            f.close()
            return delegations
        except OSError, e:
            print repr(e)

    def load_all_delegations(self, delegation_urls):
        """ Load all delegations into memory. """
        delegations = []
        for url in delegation_urls.split():
            filename = url.rpartition('/')[-1]
            if self.verbose:
                print "Attempting to load delegation file into " \
                        + "memory: " + filename
            delegations.append(self.load_delegation(self.cache_dir + \
                    filename))
        return delegations

    def download_country_code_file(self):
        """ Download and save the latest opencountrycode
            TXT(';'-separated) file """
        url = "http://www.iso.org/iso/list-en1-semic-3.txt"
        print "Fetching " + url
        text_content = self.fetch(url)
        self.write_to_a_text_file(self.cache_dir + "countrycodes.txt", \
                text_content)

    def extract_info_from_lir_file_and_insert_into_sqlite(self, filename):
        block = []
        country = ""
        entry = False
        version = ""
        for line in open(self.cache_dir + filename, "r"):
            line = line.replace("\n", "")
            if line == "":
                entry = False
                country, block, version = "", [], ""
            elif not entry and "inetnum:" in line:
                try:
                    line = line.replace("inetnum:", "").strip()
                    start_addr = line.split("-")[0].strip()
                    end_addr = line.split("-")[1].strip()
                    start_num = int(ipaddr.IPv4Address(start_addr))
                    end_num = int(ipaddr.IPv4Address(end_addr))
                    num_ips = end_num - start_num + 1
                    block = [start_addr, num_ips]
                    entry = True
                    version = "4"
                except Exception, e:
                    if self.verbose:
                        print repr(e), line
            elif not entry and "inet6num:" in line:
                try:
                    block = line.replace("inet6num:", \
                            "").strip().split("/")
                    entry = True
                    version = "6"
                except Exception, e:
                    if self.verbose:
                        print repr(e), line
            elif entry and "country:" in line:
                country = line.replace("country:", "").strip()
                data = (country, block[0], block[1], version)
                self.database_cache.insert_lir_delegation(data)

    def create_db_and_insert_delegation_into_db(self, delegation_urls):
        self.database_cache.create_sql_database()
        delegations = self.load_all_delegations(delegation_urls)
        rows = []
        for delegation in delegations:
            for entry in delegation:
                registry = str(entry['registry'])
                if not registry.isdigit() and str(entry['cc']) != "*":
                    temp_row = [entry['registry'], entry['cc'], \
                            entry['start'], entry['value'], \
                            entry['date'], entry['status'], entry['type']]
                    rows.append(temp_row)
        self.database_cache.insert_into_sql_database(rows)

class Lookup:
    def __init__(self, cache_dir, database_cache, verbose=False):
        self.cache_dir = cache_dir
        self.database_cache = database_cache
        self.verbose = verbose
        self.map_co = None
        self.build_country_code_dictionary()

    def build_country_code_dictionary(self):
        """ Return a dictionary mapping country name to the country
            code. """
        if not os.path.exists(self.cache_dir + "countrycodes.txt"):
            return
        self.map_co = {}
        txt_file = str(self.cache_dir) + "countrycodes.txt"
        for line in open(txt_file, 'r'):
            line = line.replace("\n", "").replace("\r", "")
            if line.startswith("This list states the country"):
                continue
            if line == "" or ";" not in line:
                continue
            name, code = line.split(";")
            """ capitalize the individual parts of the country name """
            name = ' '.join([part.capitalize() for part in \
                    name.split(" ")])
            self.map_co[name] = code

    def knows_country_names(self):
        return self.map_co is not None

    def get_name_from_country_code(self, cc_code):
        if not self.knows_country_names():
            return
        country_name = [(key, value) for (key, value) in \
                self.map_co.items() if value == cc_code]
        if len(country_name) > 0:
            return country_name[0][0]

    def get_country_code_from_name(self, country_name):
        """ Return the country code for a given country name. """
        if not self.knows_country_names():
            return
        cc_code = [self.map_co[key] for key in self.map_co.keys() if \
                key.upper().startswith(country_name.upper())]
        if len(cc_code) > 0:
            return cc_code[0]

    def geoip_lookup(self, ip_addr):
        # This would work with the CVS version of the GeoIP code
        # However, MaxMind hasn't done a release in a long time.
        # http://geoip.cvs.sourceforge.net/viewvc/geoip/python/\
        # test_v6.py?revision=1.1&view=markup
        #        gi = GeoIP.open(self.cache_dir + \
        #                "GeoIPv6.dat", GeoIP.GEOIP_STANDARD)
        #        cc = gi.country_code_by_addr_v6(ip_addr)
        #        cc_name = gi.country_name_by_addr_v6(ip_addr)
        gi = GeoIP.open(self.cache_dir + "GeoIP.dat", \
                GeoIP.GEOIP_STANDARD)
        cc = gi.country_code_by_addr(ip_addr)
        cc_name = gi.country_name_by_addr(ip_addr)
        return cc, cc_name

    def lookup_ipv6_address(self, ip_addr):
        print "Reverse lookup for: " + ip_addr
        split_addr = ip_addr.split(":")
        for i in ["RIR", "LIR"]:
            ip_query = ip_addr.split(":")[0] + ":" + \
                    ip_addr.split(":")[1] + "%"
            cc = self.database_cache.rir_or_lir_lookup_ipv6(ip_addr, \
                    ip_query, i)
            if cc:
                print i, "country code:", cc
                cn = self.get_name_from_country_code(cc)
                if cn:
                    print i, "country name:", cn
            else:
                ip_query = ip_addr.split(":")[0] + ":%"
                cc = self.database_cache.rir_or_lir_lookup_ipv6(ip_addr, \
                        ip_query, i)
                print i, "country code:", cc
                cn = self.get_name_from_country_code(cc)
                if cn:
                    print i, "country name:", cn

    def lookup_ipv4_address(self, ip_addr):
        print "Reverse lookup for: " + ip_addr
        if GeoIP:
            geoip_cc, geoip_cc_name = self.geoip_lookup(ip_addr)
            print "GeoIP country code: " + str(geoip_cc)
            print "GeoIP country name: " + str(geoip_cc_name)
        rir_cc = self.database_cache.rir_lookup(ip_addr)
        if rir_cc:
            print 'RIR country code:', rir_cc
            rir_cn = self.get_name_from_country_code(rir_cc)
            if rir_cn:
                print 'RIR country:', rir_cn
        else:
            print 'Not found in RIR db'
        lir_cc = self.database_cache.lir_lookup(ip_addr)
        if lir_cc:
            print 'LIR country code:', lir_cc
            lir_cn = self.get_name_from_country_code(lir_cc)
            if lir_cn:
                print 'LIR country:', lir_cn
        if GeoIP:
            if geoip_cc != rir_cc:
                print "It appears that the RIR data conflicts with the " \
                        "GeoIP data.  The GeoIP data is likely closer " \
                        "to being correct due to sub-delegation issues " \
                        "with LIR databases."

    def lookup_ip_address(self, ip_addr):
        """ Return the country code and name for a given ip address.
            Attempts to use GeoIP if available. """
        try:
            lookup_ipaddr = ipaddr.IPAddress(ip_addr)
            if isinstance(lookup_ipaddr, ipaddr.IPv4Address):
                self.lookup_ipv4_address(ip_addr)
            elif isinstance(lookup_ipaddr, ipaddr.IPv6Address):
                self.lookup_ipv6_address(ip_addr)
            else:
                print "Did not recognize '%s' as either IPv4 or IPv6 " \
                        "address." % ip_addr
        except ValueError, e:
            print "'%s' is not a valid IP address." % ip_addr

    def asn_lookup(self, asn):
        asn_cc = self.database_cache.asn_lookup(asn)
        if asn_cc:
            print "AS country code: %s" % asn_cc
            asn_cn = self.get_name_from_country_code(asn_cc)
            if asn_cn:
                print "AS country name: %s" % asn_cn
        else:
            print "AS%s not found!" % asn

    def fetch_rir_blocks_by_country(self, request, country):
        return self.database_cache.use_sql_database(request, country)

def main():
    """ Where the magic starts. """
    usage = "Usage: %prog [options]\n\n" \
            "Example: %prog -v -t mm"
    parser = optparse.OptionParser(usage)
    parser.add_option("-v", "--verbose", action="store_true", \
            dest="verbose", help = "be verbose", default=False)
    parser.add_option("-c", "--cache-dir", action="store", dest="dir", \
            help="set cache directory [default: %default]", \
            default=str(os.path.expanduser('~')) + "/.blockfinder/")
    parser.add_option("--user-agent", action="store", dest="ua", \
            help=('provide a User-Agent which will be used when '
                  'fetching delegation files [default: "%default"]'), \
            default="Mozilla/5.0")
    parser.add_option("-x", "--hack-the-internet", action="store_true", \
            dest="hack_the_internet", help=optparse.SUPPRESS_HELP)
    group = optparse.OptionGroup(parser, "Cache modes",
            "Pick at most one of these modes to initialize or update " \
            "the local cache.  May not be combined with lookup modes.")
    group.add_option("-i", "--init-rir", \
            action="store_true", dest="init_del", \
            help="initialize or update delegation information")
    group.add_option("-d", "--reload-rir", action="store_true", \
            dest="reload_del", \
            help="use existing delegation files to update the database")
    group.add_option("-l", "--init-lir", action="store_true", \
            dest="init_lir",
            help=("initialize or update lir information; can take up to "
                  "5 minutes"))
    group.add_option("-z", "--reload-lir", action="store_true",
            dest="reload_lir", \
            help=("use existing lir files to update the database; can "
                  "take up to 5 minutes"))
    group.add_option("-o", "--download-cc", action="store_true",
            dest="download_cc", help="download country codes file")
    parser.add_option_group(group)
    group = optparse.OptionGroup(parser, "Lookup modes",
            "Pick at most one of these modes to look up data in the " \
            "local cache.  May not be combined with cache modes.")
    group.add_option("-4", "--ipv4", action="store", dest="ipv4", \
            help=("look up country code and name for the specified IPv4 "
                  "address"))
    group.add_option("-6", "--ipv6", action="store", dest="ipv6", \
            help=("look up country code and name for the specified IPv6 "
                  "address"))
    group.add_option("-a", "--asn", action="store", dest="asn", \
            help="look up country code and name for the specified ASN")
    group.add_option("-t", "--code", action="store", dest="cc", \
            help=("look up all allocations in the delegation cache for "
                  "the specified two-letter country code"))
    group.add_option("-n", "--name", action="store", dest="cn", \
            help=("look up all allocations in the delegation cache for "
                  "the specified full country name"))
    parser.add_option_group(group)
    group = optparse.OptionGroup(parser, "Network modes")
    (options, args) = parser.parse_args()
    if options.hack_the_internet:
        print "all your bases are belong to us!"
        sys.exit(0)
    options_dict = vars(options)
    modes = 0
    for mode in ["init_del", "init_lir", "reload_del", "reload_lir",
                 "download_cc", "ipv4", "ipv6", "asn", "cc", "cn"]:
        if options_dict.has_key(mode) and options_dict.get(mode):
            modes += 1
    if modes > 1:
        parser.error("only 1 cache or lookup mode allowed")
    elif modes == 0:
        parser.error("must provide 1 cache or lookup mode")
    database_cache = DatabaseCache(options.dir, options.verbose)
    database_cache.connect_to_database()
    downloader_parser = DownloaderParser(options.dir, database_cache, \
            options.ua)
    lookup = Lookup(options.dir, database_cache)
    delegation_urls = """
        ftp://ftp.arin.net/pub/stats/arin/delegated-arin-latest
        ftp://ftp.ripe.net/ripe/stats/delegated-ripencc-latest
        ftp://ftp.afrinic.net/pub/stats/afrinic/delegated-afrinic-latest
        ftp://ftp.apnic.net/pub/stats/apnic/delegated-apnic-latest
        ftp://ftp.lacnic.net/pub/stats/lacnic/delegated-lacnic-latest
    """
    geoip_country_urls = """http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz
    http://geolite.maxmind.com/download/geoip/database/GeoIPv6.dat.gz"""
    lir_urls = """ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inetnum.gz
    ftp://ftp.ripe.net/ripe/dbase/split/ripe.db.inet6num.gz"""
    delegation_files = []
    for url in delegation_urls.split():
        filename = url.rpartition('/')
        delegation_files.append(filename[-1])
    downloader_parser.create_blockfinder_cache_dir()
    if options.ipv4 or options.ipv6 or options.asn or options.cc \
            or options.cn:
        if downloader_parser.cache_is_dated(delegation_files):
            print "Your delegation cache is older than 24 hours; you " \
                    "probably want to update it."
    if options.asn:
        lookup.asn_lookup(options.asn)
    elif options.ipv4:
        lookup.lookup_ip_address(options.ipv4)
    elif options.ipv6:
        lookup.lookup_ip_address(options.ipv6)
    elif options.cc or options.cn:
        country = None
        if options.cc:
            country = options.cc.upper()
        elif not lookup.knows_country_names():
            print "Need to download country codes first before looking " \
                    "up countries by name."
        else:
            country = lookup.get_country_code_from_name(options.cn)
            if not country:
                print "It appears your search did not match a country."
        if country:
            for request in ["ipv4", "ipv6", "asn"]:
                print "\n".join(lookup.fetch_rir_blocks_by_country(\
                        request, country))
    elif options.init_del or options.reload_del:
        if options.init_del:
            if GeoIP:
                downloader_parser.update_geoip_cache(geoip_country_urls)
            downloader_parser.update_delegation_cache(delegation_urls)
            if options.verbose:
                lookup.verify_cache(delegation_files)
        downloader_parser.create_db_and_insert_delegation_into_db(\
                delegation_urls)
    elif options.init_lir or options.reload_lir:
        if options.init_lir:
            downloader_parser.update_lir_delegation_cache(lir_urls)
        print "Extracting and inserting information from the lir files " \
                "can take up to 5 minutes"
        database_cache.create_or_replace_lir_table_in_db()
        for fname in "ripe.db.inetnum ripe.db.inet6num".split():
            downloader_parser.extract_info_from_lir_file_and_insert_into_sqlite(fname)
    elif options.download_cc:
        downloader_parser.download_country_code_file()
    database_cache.commit_and_close_database()

if __name__ == "__main__":
    main()

